{"componentChunkName":"component---src-templates-blog-post-js","path":"/week_4/","result":{"data":{"site":{"siteMetadata":{"title":"Antony's Blog"}},"markdownRemark":{"id":"9e820d4d-9af4-51bf-8dc3-21092a7ed25c","excerpt":"Deploy Machine Learning Model for simple use. Part II \nHai,Everyone ðŸ‘‹ ,\nWithout further adieu let us get started.\nwe have already set up the flask app and HTMLâ€¦","html":"<h2>Deploy Machine Learning Model for simple use. Part II</h2>\n<p><code class=\"language-text\">4th week of blogging</code><br>\nHai,Everyone ðŸ‘‹ ,<br>\nWithout further adieu let us get started.<br>\nwe have already set up the flask app and HTML to get the input,  now lets put the model to work.\nTo put our Model we will create a file called decision.py and import it in from decision import Emotion in our  flask_app.py file.\nTo load model</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> json\n\t<span class=\"token keyword\">import</span> keras\n\t<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\t<span class=\"token keyword\">import</span> sklearn\n\t<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> LabelBinarizer\n\t<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> LabelEncoder\n\t<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Input<span class=\"token punctuation\">,</span> Embedding<span class=\"token punctuation\">,</span> SpatialDropout1D<span class=\"token punctuation\">,</span> LSTM\n\t<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> GlobalAveragePooling1D<span class=\"token punctuation\">,</span> GlobalMaxPooling1D\n\t<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Bidirectional<span class=\"token punctuation\">,</span> Conv1D<span class=\"token punctuation\">,</span> Dense<span class=\"token punctuation\">,</span> concatenate\n\t<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Model\n\t<span class=\"token keyword\">import</span> pickle\n\t<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>sequence <span class=\"token keyword\">import</span> pad_sequences\n\t<span class=\"token keyword\">import</span> os\n\tTHIS_FOLDER <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>dirname<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>abspath<span class=\"token punctuation\">(</span>__file__<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\t \n\t<span class=\"token keyword\">def</span> <span class=\"token function\">token</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\t <span class=\"token builtin\">file</span> <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>THIS_FOLDER<span class=\"token punctuation\">,</span> <span class=\"token string\">'static/tokenizer.pickle'</span><span class=\"token punctuation\">)</span>\n\t infile <span class=\"token operator\">=</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">,</span><span class=\"token string\">'rb'</span><span class=\"token punctuation\">)</span>\n\t tokenizer <span class=\"token operator\">=</span> pickle<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>infile<span class=\"token punctuation\">)</span>\n\t infile<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\t <span class=\"token keyword\">return</span> tokenizer\n\t \n\t<span class=\"token keyword\">def</span> <span class=\"token function\">encoder</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\t labels <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'Happy'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Sad'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Anger'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Disgust'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Surprise'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Fear'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Bad'</span><span class=\"token punctuation\">]</span>\n\t encoder <span class=\"token operator\">=</span> LabelBinarizer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\t encoder<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>labels<span class=\"token punctuation\">)</span>\n\t <span class=\"token keyword\">return</span> encoder\n\t \n\t<span class=\"token keyword\">def</span> <span class=\"token function\">model</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\t input_length <span class=\"token operator\">=</span> <span class=\"token number\">428</span>\n\t input_dim <span class=\"token operator\">=</span> <span class=\"token number\">203169</span>\n\t num_classes <span class=\"token operator\">=</span> <span class=\"token number\">7</span>\n\t embedding_dim <span class=\"token operator\">=</span> <span class=\"token number\">500</span>\n\t lstm_units <span class=\"token operator\">=</span> <span class=\"token number\">128</span>\n\t lstm_dropout <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span>\n\t recurrent_dropout <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span>\n\t filters<span class=\"token operator\">=</span><span class=\"token number\">64</span>\n\t kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span>\n\t input_layer <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>input_length<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\t output_layer <span class=\"token operator\">=</span> Embedding<span class=\"token punctuation\">(</span>\n\t input_dim<span class=\"token operator\">=</span>input_dim<span class=\"token punctuation\">,</span>\n\t output_dim<span class=\"token operator\">=</span>embedding_dim<span class=\"token punctuation\">,</span>\n\t input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>input_length<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span>\n\t <span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>input_layer<span class=\"token punctuation\">)</span>\n\t output_layer <span class=\"token operator\">=</span> Bidirectional<span class=\"token punctuation\">(</span>\n\t LSTM<span class=\"token punctuation\">(</span>lstm_units<span class=\"token punctuation\">,</span> return_sequences<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n\t dropout<span class=\"token operator\">=</span>lstm_dropout<span class=\"token punctuation\">,</span> recurrent_dropout<span class=\"token operator\">=</span>recurrent_dropout<span class=\"token punctuation\">)</span>\n\t <span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output_layer<span class=\"token punctuation\">)</span>\n\t output_layer <span class=\"token operator\">=</span> Conv1D<span class=\"token punctuation\">(</span>filters<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span>kernel_size<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'valid'</span><span class=\"token punctuation\">,</span>\n\t kernel_initializer<span class=\"token operator\">=</span><span class=\"token string\">'glorot_uniform'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output_layer<span class=\"token punctuation\">)</span>\n\t \n\t avg_pool <span class=\"token operator\">=</span> GlobalAveragePooling1D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output_layer<span class=\"token punctuation\">)</span>\n\t max_pool <span class=\"token operator\">=</span> GlobalMaxPooling1D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output_layer<span class=\"token punctuation\">)</span>\n\t output_layer <span class=\"token operator\">=</span> concatenate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>avg_pool<span class=\"token punctuation\">,</span> max_pool<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\t \n\t output_layer <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span>num_classes<span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output_layer<span class=\"token punctuation\">)</span>\n\t model <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span>input_layer<span class=\"token punctuation\">,</span> output_layer<span class=\"token punctuation\">)</span>\n\t <span class=\"token builtin\">file</span> <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>THIS_FOLDER<span class=\"token punctuation\">,</span> <span class=\"token string\">'static/model.h5'</span><span class=\"token punctuation\">)</span>\n\t model<span class=\"token punctuation\">.</span>load_weights<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span>\n\t <span class=\"token keyword\">return</span> model\n\t \n\t \n\t<span class=\"token keyword\">class</span> <span class=\"token class-name\">Emotion</span><span class=\"token punctuation\">:</span>\n\t \n\t \n\t \n\t <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\t self<span class=\"token punctuation\">.</span>model <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\t self<span class=\"token punctuation\">.</span>tokenizer <span class=\"token operator\">=</span> token<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\t self<span class=\"token punctuation\">.</span>encoder <span class=\"token operator\">=</span> encoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\t \n\t <span class=\"token keyword\">def</span> <span class=\"token function\">test</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\t labels <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'Happy'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Sad'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Anger'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Disgust'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Surprise'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Fear'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Bad'</span><span class=\"token punctuation\">]</span>\n\t tokenized <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>tokenizer<span class=\"token punctuation\">.</span>texts_to_sequences<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>text<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\t pad_data <span class=\"token operator\">=</span> pad_sequences<span class=\"token punctuation\">(</span>tokenized<span class=\"token punctuation\">,</span><span class=\"token number\">428</span><span class=\"token punctuation\">)</span>\n\t pred <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>pad_data<span class=\"token punctuation\">)</span>\n\t <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">,</span>flush<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\t emotion <span class=\"token operator\">=</span> labels<span class=\"token punctuation\">[</span>np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\t confidence <span class=\"token operator\">=</span> pred<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">100</span>\n\t <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>emotion<span class=\"token punctuation\">,</span>confidence<span class=\"token punctuation\">)</span></code></pre></div>\n<p>Here we design the Model using Keras, then load the weights from the saved .h5 file\nfor easy access, we create a class for model Emotion, which contains a test method that tests the model with input after initializing model, tokenizer, encoder as the result we return emotion and confidence from the model, which is rendered with HTML for the user to view.</p>\n<h3>Deploying to Pythonanywhere</h3>\n<p>Host the script pythonanywhere by following a few simple steps:</p>\n<h4>Step 1. Sign up for a new account.</h4>\n<p>For now, letâ€™s stick with the free account. Sign up and log in to your account. Choose the flask and whichever python version you want. I will be using Python 3.7. After creating the web app, you will get a URL that points to your flask endpoint. By default, Your endpoint looks something like this: [username].pythonanywhere.com</p>\n<h4>Step 2. Upload the files</h4>\n<p>Inside the default folder â€” /mysite/ you need to upload your complete folder. You can do it either using the files page on the website or using the bash console by using wget command to download your files. and enable Force HTTPS\nFile Structure looks like this</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">/mysite/\n <span class=\"token operator\">|</span>\n +-- flask_app.py\n <span class=\"token operator\">|</span> \n +-- decision.py\n <span class=\"token operator\">|</span> \n +-- static/\n <span class=\"token operator\">|</span> <span class=\"token operator\">|</span> \n <span class=\"token operator\">|</span> +-- encoder.pickle\n <span class=\"token operator\">|</span> <span class=\"token operator\">|</span> \n <span class=\"token operator\">|</span> +-- lstm_model.h5\n <span class=\"token operator\">|</span> <span class=\"token operator\">|</span> \n <span class=\"token operator\">|</span> +-- tokenizer.pickle\n +-- templates/\n <span class=\"token operator\">|</span> <span class=\"token operator\">|</span> \n <span class=\"token operator\">|</span> +-- index.html</code></pre></div>\n<h4>Step 3. Reload the web app</h4>\n<p>Web Application is ready Now and can be used for predicting emotions of text. </p>","frontmatter":{"title":"Deploy Machine Learning Model for simple use. Part II","date":"July 13, 2020","description":"Embedding the model in the flask app and deploying it to the pythonanywhere for free"}}},"pageContext":{"slug":"/week_4/","previous":{"fields":{"slug":"/week_3/"},"frontmatter":{"title":"Deploy Machine Learning Model for simple use."}},"next":{"fields":{"slug":"/week_5/"},"frontmatter":{"title":"Marching Squares (Coding Train Inspiration)"}}}}}